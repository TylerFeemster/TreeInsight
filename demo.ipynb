{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba3a8b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-03T04:53:11.353731Z",
     "iopub.status.busy": "2025-04-03T04:53:11.353256Z",
     "iopub.status.idle": "2025-04-03T04:53:16.679624Z",
     "shell.execute_reply": "2025-04-03T04:53:16.678518Z"
    },
    "papermill": {
     "duration": 5.333227,
     "end_time": "2025-04-03T04:53:16.681820",
     "exception": false,
     "start_time": "2025-04-03T04:53:11.348593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import chi2\n",
    "\n",
    "class Files:\n",
    "    train = 'train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c9ab4",
   "metadata": {
    "papermill": {
     "duration": 0.002716,
     "end_time": "2025-04-03T04:53:16.688038",
     "exception": false,
     "start_time": "2025-04-03T04:53:16.685322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Algorithmically Identifying Feature Engineering Opportunities\n",
    "\n",
    "Let's briefly demo a method for gaining quick insight into feature relationships with predictive power in mind. I've included motivating ideas at the bottom of the notebook if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5badb0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:53:16.695284Z",
     "iopub.status.busy": "2025-04-03T04:53:16.694596Z",
     "iopub.status.idle": "2025-04-03T04:53:18.730699Z",
     "shell.execute_reply": "2025-04-03T04:53:18.729740Z"
    },
    "papermill": {
     "duration": 2.041593,
     "end_time": "2025-04-03T04:53:18.732593",
     "exception": false,
     "start_time": "2025-04-03T04:53:16.691000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(Files.train)\n",
    "target = 'Listening_Time_minutes'\n",
    "irrelevant_cols = ['id']\n",
    "\n",
    "X = data.drop(columns = irrelevant_cols + [target])\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f12888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:53:18.739763Z",
     "iopub.status.busy": "2025-04-03T04:53:18.739446Z",
     "iopub.status.idle": "2025-04-03T04:53:18.750830Z",
     "shell.execute_reply": "2025-04-03T04:53:18.749936Z"
    },
    "papermill": {
     "duration": 0.017033,
     "end_time": "2025-04-03T04:53:18.752561",
     "exception": false,
     "start_time": "2025-04-03T04:53:18.735528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def traverse(node: dict, parents: list, ancestors: list) -> None:\n",
    "    if 'split_feature' in node: # selects non-leaf nodes\n",
    "        feature = node['split_feature']\n",
    "        for parent in parents:\n",
    "            ancestors.append((parent, feature))\n",
    "        parents = parents.copy()\n",
    "        parents.append(feature)\n",
    "\n",
    "        if 'left_child' in node:\n",
    "            traverse(node['left_child'], parents, ancestors)\n",
    "        if 'right_child' in node:\n",
    "            traverse(node['right_child'], parents, ancestors)\n",
    "            \n",
    "\n",
    "def tally_results(ancestors: list) -> pd.DataFrame:\n",
    "    parent_count = {}\n",
    "    child_count = {}\n",
    "    tuple_count = {}\n",
    "    total = 0\n",
    "    for p, c in ancestors:\n",
    "        total += 1\n",
    "        parent_count[p] = 0 if p not in parent_count else parent_count[p] + 1\n",
    "        child_count[c] = 0 if c not in child_count else child_count[c] + 1\n",
    "        tuple_count[(p, c)] = 0 if (p, c) not in tuple_count else tuple_count[(p, c)] + 1\n",
    "\n",
    "    p_vals = {}\n",
    "    for (p, c), observed in tuple_count.items():\n",
    "        expected = parent_count[p] * child_count[c] / total\n",
    "        chi2_stat = (observed - expected)**2 / expected\n",
    "        p_vals[(p, c)] = 1 - chi2.cdf(chi2_stat, df=1)\n",
    "\n",
    "    df_items = [{'Parent': p, 'Child': c, 'p_value': val} for (p, c), val in p_vals.items()]\n",
    "    return pd.DataFrame(df_items)\n",
    "    \n",
    "\n",
    "def ranked_feature_relationships(X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    X, y = X.copy(), y.copy()\n",
    "    cat_cols = X.select_dtypes('object').columns.to_list()\n",
    "    X[cat_cols] = X[cat_cols].astype('category')\n",
    "\n",
    "    features = X.columns.to_list()\n",
    "\n",
    "    dtrain = lgb.Dataset(X, label=y, categorical_feature=cat_cols)\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"verbose\": -1,\n",
    "        \"max_depth\": 3, # feel free to edit: I find shallow trees are better for pulling out key relationships\n",
    "    }\n",
    "    model = lgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "    trees = model.dump_model()[\"tree_info\"]\n",
    "    ancestors = []\n",
    "    for tree in trees:\n",
    "        parents = []\n",
    "        traverse(tree['tree_structure'], parents, ancestors)\n",
    "\n",
    "    p_values = tally_results(ancestors)\n",
    "    p_values[['Parent', 'Child']] = p_values[['Parent', 'Child']].map(lambda x: features[x])\n",
    "    p_values = p_values.sort_values('p_value', ascending=True).reset_index(drop=True)\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63015fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:53:18.759425Z",
     "iopub.status.busy": "2025-04-03T04:53:18.759073Z",
     "iopub.status.idle": "2025-04-03T04:53:21.789849Z",
     "shell.execute_reply": "2025-04-03T04:53:21.788723Z"
    },
    "papermill": {
     "duration": 3.036176,
     "end_time": "2025-04-03T04:53:21.791717",
     "exception": false,
     "start_time": "2025-04-03T04:53:18.755541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parent</th>\n",
       "      <th>Child</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Episode_Length_minutes</td>\n",
       "      <td>Number_of_Ads</td>\n",
       "      <td>2.944100e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Podcast_Name</td>\n",
       "      <td>Episode_Title</td>\n",
       "      <td>9.686866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Episode_Length_minutes</td>\n",
       "      <td>Episode_Title</td>\n",
       "      <td>2.770240e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Episode_Sentiment</td>\n",
       "      <td>Guest_Popularity_percentage</td>\n",
       "      <td>6.981304e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Host_Popularity_percentage</td>\n",
       "      <td>Number_of_Ads</td>\n",
       "      <td>1.084662e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Episode_Length_minutes</td>\n",
       "      <td>Guest_Popularity_percentage</td>\n",
       "      <td>1.394573e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Podcast_Name</td>\n",
       "      <td>Number_of_Ads</td>\n",
       "      <td>1.448542e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number_of_Ads</td>\n",
       "      <td>Episode_Title</td>\n",
       "      <td>1.507850e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Episode_Sentiment</td>\n",
       "      <td>Host_Popularity_percentage</td>\n",
       "      <td>2.232855e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Episode_Sentiment</td>\n",
       "      <td>Publication_Time</td>\n",
       "      <td>4.768292e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Parent                        Child       p_value\n",
       "0       Episode_Length_minutes                Number_of_Ads  2.944100e-08\n",
       "1                 Podcast_Name                Episode_Title  9.686866e-04\n",
       "2       Episode_Length_minutes                Episode_Title  2.770240e-03\n",
       "3            Episode_Sentiment  Guest_Popularity_percentage  6.981304e-03\n",
       "4   Host_Popularity_percentage                Number_of_Ads  1.084662e-02\n",
       "5       Episode_Length_minutes  Guest_Popularity_percentage  1.394573e-02\n",
       "6                 Podcast_Name                Number_of_Ads  1.448542e-02\n",
       "7                Number_of_Ads                Episode_Title  1.507850e-02\n",
       "9            Episode_Sentiment   Host_Popularity_percentage  2.232855e-02\n",
       "10           Episode_Sentiment             Publication_Time  4.768292e-02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vals = ranked_feature_relationships(X, y)\n",
    "p_vals.query('Parent != Child and p_value < 0.05').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40262a",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2025-04-03T04:53:21.798016",
     "exception": false,
     "start_time": "2025-04-03T04:53:21.795049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is empirical evidence that we should spend some time looking into combining these feature pairs.\n",
    "\n",
    "0. The model likes splitting on `Number_of_Ads` after `Episode_Length_minutes` has been refined. This is intuitive; ad frequency is a more important measure.\n",
    "1. For those who've done some EDA, (`Podcast_Name`, `Episode_Title`) is not uniquely identifying. In fact, each pair has lots of datapoints. We can experiment with feature concatenation here.\n",
    "2. This is less intuitive; something to explore further... maybe some categorical or target encoding here?\n",
    "3. Again, less obvious. Maybe listeners who like the guest are willing to put up with a less enjoyable listening experience for longer? Since `Episode_Sentiment` has only three categories, we could try many encoding schemes.\n",
    "4. Go forth and explore. Adventure is out there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9b1e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:53:21.805359Z",
     "iopub.status.busy": "2025-04-03T04:53:21.804977Z",
     "iopub.status.idle": "2025-04-03T04:53:21.817053Z",
     "shell.execute_reply": "2025-04-03T04:53:21.816000Z"
    },
    "papermill": {
     "duration": 0.017576,
     "end_time": "2025-04-03T04:53:21.818706",
     "exception": false,
     "start_time": "2025-04-03T04:53:21.801130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parent</th>\n",
       "      <th>Child</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Podcast_Name</td>\n",
       "      <td>Podcast_Name</td>\n",
       "      <td>0.019126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Parent         Child   p_value\n",
       "8  Podcast_Name  Podcast_Name  0.019126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vals.query('Parent == Child and p_value < 0.05').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186c754",
   "metadata": {
    "papermill": {
     "duration": 0.002821,
     "end_time": "2025-04-03T04:53:21.824830",
     "exception": false,
     "start_time": "2025-04-03T04:53:21.822009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that the model likes to split on `Podcast_Name` more than once. This suggests there are clustering and/or encoding opportunities here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64752bc4",
   "metadata": {
    "papermill": {
     "duration": 0.002756,
     "end_time": "2025-04-03T04:53:21.830706",
     "exception": false,
     "start_time": "2025-04-03T04:53:21.827950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I'm hoping to build on this in the near future, so let me know if you have any suggestions for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13241b6",
   "metadata": {
    "papermill": {
     "duration": 0.002968,
     "end_time": "2025-04-03T04:53:21.836676",
     "exception": false,
     "start_time": "2025-04-03T04:53:21.833708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Background and Justification\n",
    "\n",
    "Ordinary metrics like correlation are pretty limited when it comes to identifying feature relationships. A much better metric is something like mutual information, but it relies on distribution approximations. Plus, it's more reliable for binary relationships, like I(X, Y) or I(X1, X2). The first of these is rarely necessary since we can plot Y vs X, and the second doesn't promise application to the problem of predicting Y.\n",
    "\n",
    "The reason MI is so powerful, especially for something like tabular data, is that it is invariant to monotonic transformations of the variables. Unlike correlation, it doesn't need its variables to be linearly related. Decision trees exhibit this same phenomenon, invariance under monotonic transformations. This, I believe, is the reason for the empirical superiority of decision trees in tabular prediction.\n",
    "\n",
    "For categorical data, we don't need complex distribution approximations; we can simply get the frequency counts. The chi-squared test is a well-understood empirical method for addressing the question of two categorical features being related. Indeed, it answers the same question as MI: how far does the empirical, 2D-distribution drift from the assumption of independence? Chi-squared tests allow us to easily convert these results into a probability, or p-value.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is an art. We might start with some visualizations, intuitive experiments, domain knowledge, statistics, etc. to help us navigate the endless combinations. But the curse of dimensionality is always with us. This motivates a strategic approach that:\n",
    "1. Identifies strong feature relationships,\n",
    "2. Promises performance improvements.\n",
    "\n",
    "\n",
    "The method described in this notebook for achieving these ends can be summarized as follows:\n",
    "1. Train a gradient-boosted decision trees model on the data.\n",
    "2. Traverse the trees, recording every time a split is a direct or indirect descendant of another.\n",
    "3. Go through the pairs, recording how often each feature is a parent or child.\n",
    "4. Estimate the expected pair frequency of (p, c) given empirical parent and child counts for p and c, respectively.\n",
    "5. Perform a chi-squared test with the observed (p, c) counts.\n",
    "6. Convert to p-values and start feature engineering.\n",
    "\n",
    "Note that even with both numerical and categorical columns, we're looking only at the feature relationships via the split structure of the trees.\n",
    "\n",
    "When a split is a descendant of another, the incoming data is filterd by the earlier split. So, when the probability of a split becomes more likely given another (informed by chi-squared), we know that there is mutual information. More importantly, we know that this mutual information is relevant for predicting Y. In terms of mutual information, we're finding those parent-child pairs such that\n",
    "$$I(X_{child} \\text{ }; Y \\text{ }|\\text{ } X_{parent}) \\ge I(X_{child} \\text{ }; Y).$$\n",
    "These are the pairs that promise us the most performance improvement when combined effectively. To be clear, there's still work to be done, but knowing which pairs to investigate closely yields a massive speed-up. In some cases, we can identify opportunities we might not have tried otherwise."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11351736,
     "sourceId": 91715,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.229728,
   "end_time": "2025-04-03T04:53:22.762873",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-03T04:53:08.533145",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
